---
title: "Project Report"
author: "Tim, Xiaofan, Yanwen, Jingning"
date: "11/20/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(hms)
library(ggplot2)
library(dplyr)
library(cowplot)
library(lavaan)
library(magrittr)
library(tidyr)
library(knitr)
library(abind)
library(kableExtra)
survey <- read.csv("survey.csv")
```

# Introduction
Client is investigating how foreign language teachers feel about and utilize methods from the Teacher Effectiveness for Language Learning (TELL), and seeking advice about how to improving the survey.

Our purpose for our client in this project: 
1.  A lot of people don’t answer the survey because it’s long. Can we reduce the number of questions?
2.  Is the survey currently answering the research questions?


# EDA & Conerns

## Data Structure

We are provided the data in an excel file with 6 spreadsheets including one sheet of notes, one sheet of personal information and 4 sheets of Teacher Effectiveness for Language Learning (TELL) framework survey questions. The dataset of personal information contains questions regarding respondents' teaching language and education background. The dataset of Teacher Effectiveness for Language Learning (TELL) framework survey contains around 200 questions asking about respondents' attitudes of contribution and confidence towards each practice in the framework. There are 4 domains of Teacher Effectiveness for Language Learning (TELL) survey questions: planning, learning experience, learning tools, and performance & feedback. Each domain contains several subdomains and each subdomain contains a different number of questions. For this project, we focus on reducing the number of questions in the dataset of Teacher Effectiveness for Language Learning (TELL) framework survey.

## EDA 

We conduct a basic Exploratory Data Analysis (EDA) for this project. Firstly, We focus on the time for respondents to complete this survey.

```{r, message=FALSE, echo=FALSE}
library(lubridate)
library(hms)
library(ggplot2)
library(dplyr)
library(cowplot)
survey <- read.csv("survey.csv")

#Uniform newest part time into POSIX objects:
survey$Start.Date <- strptime(survey$Start.Date, format = "%m/%d/%Y %H:%M:%S")
survey$End.Date <- strptime(survey$End.Date, format = "%m/%d/%Y %H:%M:%S")
#Time people used to finish the survey:
survey$time <- as.numeric(round(abs(difftime(survey$End.Date, survey$Start.Date, units = "mins")),2))

#Count number of NA values in rows:
survey$num <- apply(survey, MARGIN = 1, FUN=function(x) length(x[is.na(x)]))

#graph the plot:
graph <- ggplot(survey, aes(x=time, y=num)) +
  geom_point(na.rm = TRUE)
graph <- graph + labs(x = "Time people used in survey(min)", y = "Number of questions they didn't answer") 
graph

time <- as.data.frame(na.omit(survey$time))
time$num <- survey$num[1:74]
colnames(time)[1] <- "Time people used(minutes)"
colnames(time)[2] <- "# of unanswered questions"

par(mfrow=c(2,4))
session1 <- filter(time,`Time people used(minutes)` <= 15)
session2 <- filter(time, `Time people used(minutes)` > 15 & `Time people used(minutes)` <= 30)
session3 <- filter(time, `Time people used(minutes)` > 30 & `Time people used(minutes)` <= 60)
session4 <- filter(time, `Time people used(minutes)` > 60 & `Time people used(minutes)` <= 1000)
session5 <- filter(time, `Time people used(minutes)` > 1000 & `Time people used(minutes)` <= 1600)
#From 0-15min:
p1 <- ggplot(session1, aes(x=`Time people used(minutes)`, y=`# of unanswered questions`)) + 
  geom_bar(stat = "identity") + ggtitle("Time used in 0-15 minutes") 
#From 15-30min:
p2 <- ggplot(session2, aes(x=`Time people used(minutes)`, y=`# of unanswered questions`)) + 
  geom_bar(stat = "identity") + ggtitle("Time used in 16-30 munites")
#From 31-60min:
p3 <- ggplot(session3, aes(x=`Time people used(minutes)`, y=`# of unanswered questions`)) + 
  geom_bar(stat = "identity") + ggtitle("Time used in 31-60 munites")
#From 61-120min:
p4 <- ggplot(session4, aes(x=`Time people used(minutes)`, y=`# of unanswered questions`)) + 
  geom_bar(stat = "identity") + ggtitle("Time used in 61-400 munites")
#From 121-300min:
p5 <- ggplot(session5, aes(x=`Time people used(minutes)`, y=`# of unanswered questions`)) + 
  geom_bar(stat = "identity") + ggtitle("Time used in 401-1600 munites")

plot_grid(p1, p2, p3, p4, p5, nrow = 3, ncol = 2)
```


## Data Cleaning


## Concerns

We come up with several concerns after the initial EDA. Firstly, the observations we can use in the analysis are very limited since there are many N/A in the dataset. Secondly, some respondents seem like choosing the same answer through the whole survey and if we identify these answers as non-valid, then our sample size would become even smaller. With this limited sample size, the accuracy and reference of results from our subsequent analysis could be affected.

# Method we used 

We will use Confirmatory Factor Analysis (CFA) to reduce the survey questions number.  CFA is a special form of factor analysis and mostly used in social science research. It is used to check whether measures of a construct are consistent with a researcher's understanding of the nature of that construct.  
Here we will use CFA to see if there are survey questions equivalent to each other so we can reduce those repeated questions. We will analysis each subdomain separately and will only consider the problems regarding confidence or not. Within each subdomain, there will be several questions and our null hypothesis is that all survey questions are identical to each other. Then our alternative hypothesis is that the questions are not all equal.  
We will focus on the p value result we have from CFA and we will take a p value larger than 0.05 to reject our null hypothesis. When we are not able to reject our null hypothesis, we will look at our factor loading to check the correlations between questions. Then we will fit new model by dropping question with lowest factor loading and see if we will reject our null hypothesis now. We will keep doing this until we have a subdomain with an acceptable p value, which gives us a set of survey questions are not identical to each other.


# Analysis

```{r echo=FALSE, message=FALSE, warning=FALSE}
rowclean <- function(filename) {
  data <- read.csv(paste0(filename),na.string=c("","NA"))
  rownum <- max(which(is.na(data[2,])==F))
  clean <- data[,1:rownum]
  colnames(clean) = NULL
  names1 <- clean[1,1:5]
  names2 <- clean[2,6:rownum]
  names<- cbind(names1, names2)
  clean <- clean[3:nrow(clean),]
  colnames(clean) <- c(t(names))
  return(clean)
}

filenames <- list.files()
selectfiles <- filenames[grep("TELL Statements",filenames,perl=FALSE)]
resultlist <- vector("list",length(selectfiles))

for(i in 1:length(selectfiles)) {
  resultlist[[i]] <- rowclean(selectfiles[i])
}

aggregate <- abind(resultlist, along=2,force.array=F)

personinfo <- aggregate[,1:5]
surveyanswers <- aggregate[,-which(names(aggregate) %in% names(personinfo))]
survey <- cbind(personinfo,surveyanswers)
colnames(surveyanswers)[c(grep("LT1a _Confidence",colnames(surveyanswers)))] <- "LT1a_Confidence"
colnames(surveyanswers)[c(grep("LT5c_Contributes.1",colnames(surveyanswers)))] <- "LT56c_Confidence"

data.LT <- surveyanswers[,c(grep("LT",colnames(surveyanswers)))]
data.LT <- data.LT[,c(grep("Confidence",colnames(data.LT)))]
ans = c("I'm not sure what this means", "Not confident at all","Somewhat confident","Neutral","Confident","Very Confident")
LT.ordered <- data.LT
LT.numer <- data.LT
for (i in 1:ncol(data.LT)) {
  LT.ordered[,i] <- factor(data.LT[,i],levels=ans)
  LT.numer[,i] <- as.numeric(LT.ordered[,i])
}
colnames(LT.numer) <- colnames(data.LT)

```

## Learning Tool Domain Analysis

```{r echo=FALSE, message=FALSE, warning=FALSE}
LT1 <- 'lt1 =~ aa*LT1a_Confidence + aa*LT1b_Confidence + LT1c_Confidence '
fit1 <- cfa(LT1,data=LT.numer,std.lv=T)
summary(fit1,standardized=T)
fitMeasures(fit1)
modificationIndices(fit1)
parameterEstimates(fit1,standardized=T) %>%
  filter(op=="=~") %>%
  select('Latent Factor'=lhs,Indicator=rhs,B=est,SE=se,Z=z,'p-value'=pvalue,loading=std.all) %>%
  kable(digits = 3, format="pandoc", caption="Factor Loadings")
#P-value=0.741>0.05. Factor loadings: a-0.488;b-0.472;c-0.722. cfi=1;ltli=1.607.

LT2 <- 'lt2 =~ aa*LT2a_Confidence + aa*LT2b_Confidence + LT2c_Confidence'
fit2 <- cfa(LT2,data=LT.numer,std.lv=T)
summary(fit2,standardized=T)
fitMeasures(fit2)
modificationIndices(fit2)
parameterEstimates(fit2,standardized=T) %>%
  filter(op=="=~") %>%
  select('Latent Factor'=lhs,Indicator=rhs,B=est,SE=se,Z=z,'p-value'=pvalue,loading=std.all) %>%
  kable(digits = 3, format="pandoc", caption="Factor Loadings")
#P-value=0.953>0.05. Factor loadings: a-0.587;b-0.603;c-0.817. cfi=1; tli=1.234.

LT3 <- 'lt3 =~ LT3a_Confidence + aa*LT3b_Confidence + aa*LT3d_Confidence'
fit3 <- cfa(LT3,data=LT.numer,std.lv=T)
summary(fit3,standardized=T)
fitMeasures(fit3)
modificationIndices(fit3)
parameterEstimates(fit3,standardized=T) %>%
  filter(op=="=~") %>%
  select('Latent Factor'=lhs,Indicator=rhs,B=est,SE=se,Z=z,'p-value'=pvalue,loading=std.all) %>%
  kable(digits = 3, format="pandoc", caption="Factor Loadings")
#Initial p-value with 4 questions is 0.008. 
#After dropping question c, the p-value=0.897. Factor loadings:a-0.959;b-0.802;c-0.629. cfi=1;tli=1.087.

LT4 <- 'lt4 =~ LT4a_Confidence + aa*LT4b_Confidence + aa*LT4c_Confidence'
fit4 <- cfa(LT4,data=LT.numer,std.lv=T)
summary(fit4,standardized=T)
fitMeasures(fit4)
modificationIndices(fit4)
parameterEstimates(fit4,standardized=T) %>%
  filter(op=="=~") %>%
  select('Latent Factor'=lhs,Indicator=rhs,B=est,SE=se,Z=z,'p-value'=pvalue,loading=std.all) %>%
  kable(digits = 3, format="pandoc", caption="Factor Loadings")
#P-value=0.899. Factor loadings: a-0.469;b-1.012;c-0.886. cfi=1; tli=1.06.


LT5 <- 'lt5 =~ aa*LT5a_Confidence + LT5b_Confidence + aa*LT5c_Confidence'
fit5 <- cfa(LT5,data=LT.numer,std.lv=T)
summary(fit5,standardized=T)
fitMeasures(fit5)
modificationIndices(fit5)
parameterEstimates(fit5,standardized=T) %>%
  filter(op=="=~") %>%
  select('Latent Factor'=lhs,Indicator=rhs,B=est,SE=se,Z=z,'p-value'=pvalue,loading=std.all) %>%
  kable(digits = 3, format="pandoc", caption="Factor Loadings")
#P-value=0.379. Factor loadings: a-0.618;b-0.844;c-0.532. cfi=1; tli=1.055.


```


# Conclusion / Discussion


## Appendix
